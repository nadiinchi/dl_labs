{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 3. Обучение сверточных нейросетей в Pytorch\n",
    "\n",
    "На этом семинаре мы будем обучать LeNet-5 на данных MNIST (и не только :). Мы наконец перестанем реализовывать все самостоятельно и будем пользоваться готовым функционалом pytorch.\n",
    "\n",
    "Для начала ознакомимся с парой примеров обучения модели:\n",
    "* [Пример 1](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/convolutional_neural_network/main.py)\n",
    "* [Пример 2](https://github.com/jcjohnson/pytorch-examples/blob/master/nn/two_layer_net_nn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных в pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз мы будем работать MNIST: он отличается от digits разрещением изображений (28x28 вместо 8x8) и числом объектов (60000 в обучении вместо 1797). \n",
    "\n",
    "В pytorch есть своя обертка, позволяющая скачивать MNIST, но нам будет удобнее скачать его самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо обучающей и контрольной, нам понадобится валидационная выборка, чтобы настраивать гиперпараметры. Ее можно отделить от обучающей выборки (например, 25% = 15000 объектов). Однако модель несколько долго обучается даже на 75% обучающей выборки (несколько минут), что не очень хорошо для семинара. Поэтому для валидационных целей предлагается обучающую выборку также сжать до 15000 объектов. Финальную модель будем обучать по всей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle data\n",
    "np.random.seed(0)\n",
    "idxs = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "X_train, y_train = X_train[idxs], y_train[idxs]\n",
    "                            \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pytorch есть удобный класс для генерации батчей - DataLoader. Ему на вход надо подать объект класса TensorDataset, слудащий оберткой над матрицами данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(X, y, batch_size=64):\n",
    "    train = torch.utils.data.TensorDataset(torch.from_numpy(X).float(), \n",
    "                                       torch.from_numpy(y))\n",
    "    train_loader = torch.utils.data.DataLoader(train, \n",
    "                                               batch_size=batch_size)\n",
    "    return train_loader\n",
    "\n",
    "# for final model:\n",
    "train_loader_full = get_loader(X_train, y_train) \n",
    "test_loader = get_loader(X_test, y_test)\n",
    "# for validation purposes:\n",
    "train_loader = get_loader(X_train[:15000], y_train[:15000])\n",
    "val_loader = get_loader(X_train[15000:30000], y_train[15000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check number of objects\n",
    "val_loader.dataset.data_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание модели LeNet-5\n",
    "\n",
    "Сверточный слой (из презентации Антона Осокина):\n",
    "![Слайд про свертки из презентации Антона Осокина](https://github.com/nadiinchi/dl_labs/raw/master/convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо реализовать LeNet-5:\n",
    "\n",
    "![Архитектура LeNet-5](https://cdnpythonmachinelearning.azureedge.net/wp-content/uploads/2017/09/lenet-5-825x285.png?x64257)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберите нейросеть в соответствии с изображениями и примерами кода, которые были даны выше. В качестве нелинейности используйте ReLU (после всех сверточных и полносвязных слоев). Кроме того, нейросеть должна поддерживать увеличение числа сверток во всех сверточных слоях в k раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, k=1):\n",
    "        super(CNN, self).__init__()\n",
    "        ### your code here: define layers\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        ### your code here: transform x using layers\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем параметры нейросети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(param.data.numpy().size for param \\\n",
    "               in model.parameters() if param.requires_grad)\n",
    "\n",
    "count_parameters(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # loss includes softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения модели удобно контролировать качество и на обучении, и на контроле (валидации) - возникает дублирующий код. Поэтому мы вынесем в отдельную функцию оценку модели, и в отдельную функцию - эпоху обучения. Это позволит также честно оценивать значение критерия качества на всей обучающей выборке по окончании эпохи (а не усреднять значения на минибатчах).\n",
    "\n",
    "В прототипах указано про train и eval mode: в нашем случае они не нужны (были бы нужны, если бы мы использовали дропаут или батч-нормализацию, к примеру). Но чтобы вы могли использовать этот код в будущем, лучше указывать переключение режима."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_loader):\n",
    "    \"\"\"\n",
    "    for each batch \n",
    "    performs forward and backward pass and parameters update \n",
    "    \n",
    "    Input:\n",
    "    model: instance of model (example defined above)\n",
    "    optimizer: instance of optimizer (defined above)\n",
    "    train_loader: instance of DataLoader\n",
    "    \n",
    "    Returns:\n",
    "    nothing\n",
    "    \n",
    "    Do not forget to set net to train mode!\n",
    "    \"\"\"\n",
    "    ### your code here\n",
    "    \n",
    "\n",
    "def evaluate_loss_acc(loader, model):\n",
    "    \"\"\"\n",
    "    Evaluates loss and accuracy on the whole dataset\n",
    "    \n",
    "    Input:\n",
    "    loader:  instance of DataLoader\n",
    "    model: instance of model (examle defined above)\n",
    "    \n",
    "    Returns:\n",
    "    (loss, accuracy)\n",
    "    \n",
    "    Do not forget to set net to eval mode!\n",
    "    \"\"\"\n",
    "    ### your code here\n",
    "    \n",
    "    \n",
    "def train(model, opt, train_loader, test_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    Performs training of the model and prints progress\n",
    "    \n",
    "    Input:\n",
    "    model: instance of model (example defined above)\n",
    "    opt: instance of optimizer \n",
    "    train_loader: instance of DataLoader\n",
    "    test_loader: instance of DataLoader (for evaluation)\n",
    "    n_epochs: int\n",
    "    \n",
    "    Returns:\n",
    "    4 lists: train_log, train_acc_log, val_log, val_acc_log\n",
    "    with corresponding metrics per epoch\n",
    "    \"\"\"\n",
    "    train_log, train_acc_log = [], []\n",
    "    val_log, val_acc_log = [], []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_epoch(model, opt, train_loader)\n",
    "        train_loss, train_acc = evaluate_loss_acc(train_loader, model)\n",
    "        val_loss, val_acc = evaluate_loss_acc(test_loader, model)\n",
    "\n",
    "        train_log.append(train_loss)\n",
    "        train_acc_log.append(train_acc)\n",
    "\n",
    "        val_log.append(val_loss)\n",
    "        val_acc_log.append(val_acc)\n",
    "\n",
    "        print (('Epoch [%d/%d], Loss (train/test): %.4f/%.4f,'+\\\n",
    "               ' Acc (train/test): %.4f/%.4f' )\n",
    "                   %(epoch+1, n_epochs, \\\n",
    "                     train_loss, val_loss, train_acc, val_acc))\n",
    "            \n",
    "    return train_log, train_acc_log, val_log, val_acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите нейронную сеть, используя определенные функции. Установите Adam в качестве оптимизатора, learning_rate=0.001, число эпох - 20. В качестве test_loader используйте валидационную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результат прохождения изображения через слои. Код ниже отрисовывает сетку изображений: первый столбец - изображения цифр, следующие 6 столбцов - результаты применения фильтров к ним. Чтобы им воспользоваться, сохраните в x переменную, храняющую батч из 10 изображений, в y - результат применения первого лчоя к x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for im in range(10):\n",
    "    plt.subplot(11, 7, im*7+1)\n",
    "    plt.imshow(x.data[im, 0])\n",
    "    plt.axis(\"off\")\n",
    "    for i in range(6):\n",
    "        plt.subplot(11, 7, im*7+i+2)\n",
    "        plt.imshow(y.data[im, i].numpy())\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем визуализируйте результат применения второго сверточного слоя (после всех предыдущих слоев):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Подбор длины шага и размера батча"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики точности (accuracy) на обучающей и валидационной выборке в зависимости от номера эпохи при разных параметрах обучения: learning rate$ \\in \\{0.0001, 0.001, 0.01\\}$, batch size $\\in \\{64, 256\\}$. \n",
    "\n",
    "Лучше всего отображать кривые для обучения на левом графике, кривые для валидации - на правом с общей осью y (plt.ylim).\n",
    "\n",
    "Как влияют длина шага и размер батча на итоговое качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте модифицировать архитектуру нейросети: увеличить число фильтров и уменьшить число полносвязных слоев. \n",
    "\n",
    "Впишите цифры в скобки:\n",
    "* LeNet-5 классич. (6 и 16 сверток):  качество на обучении: ( )  качество на валидации: ( )\n",
    "* Увеличение в 4 раза (24 и 64 сверток):  качество на обучении: ( )  качество на валидации: ( )\n",
    "* Удаление полносвзяного слоя: предыдущая нейросеть с 1 полносвязным слоем: качество на обучении: ( )  качество на валидации: ( )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите длину шага, размер батча и архитектуру по валидационной выборке, обучите нейросеть на полной обучающей выборке и выведите качество на контрольной выборке. Хуже ли оно, чем на валидационной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перенесение весов на Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fashion MNIST](https://www.kaggle.com/zalando-research/fashionmnist) - это датасет, аналогичный MNIST, но с изображениями элементов одежды вместо цифр. На нем также предполагается решать задачу классификации на 10 классов. Ясно, что мы можем обучить нейросеть аналогично MNIST. Но интересно исследовать, как \"сверточная\" часть обученной на MNIST нейросети может быть использована на новых, аналогичных данных. \n",
    "\n",
    "Скачайте данные по [ссылке](https://www.kaggle.com/zalando-research/fashionmnist/data) и загрузите с помощью pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fm_train = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "fm_test = pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fm_y_train = fm_train[\"label\"].values\n",
    "fm_X_train = fm_train[fm_train.columns[1:]].values.reshape(-1, 1, 28, 28)\n",
    "fm_y_test = fm_test[\"label\"].values\n",
    "fm_X_test = fm_test[fm_train.columns[1:]].values.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите любую архитектуру из обученных в предыдущем разделе и попробуйте три способа решения задачи классификации Fashion MNIST:\n",
    "* обучение нейросети \"с нуля\";\n",
    "* обучение всех слоев нейросети, но веса сверточных слоев иниициализируются обученными на MNIST, а полносвязные слои - случайно;\n",
    "* фиксирование сверточных слоев, обученных на MNIST, и обучение полносвязных слоев.\n",
    "\n",
    "Велика ли разница в полученном качестве?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
