{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      " [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "add 5 :\n",
      "[[ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]\n",
      " [17 18 19 20]]\n",
      "X*X^T  :\n",
      " [[ 14  38  62  86]\n",
      " [ 38 126 214 302]\n",
      " [ 62 214 366 518]\n",
      " [ 86 302 518 734]]\n",
      "mean over cols :\n",
      "[ 1.5  5.5  9.5 13.5]\n",
      "cumsum of cols :\n",
      "[[ 0  1  2  3]\n",
      " [ 4  6  8 10]\n",
      " [12 15 18 21]\n",
      " [24 28 32 36]]\n"
     ]
    }
   ],
   "source": [
    "# numpy world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "print(\"X :\\n %s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", np.dot(x, x.T))\n",
    "print(\"mean over cols :\\n%s\" % (x.mean(axis=-1)))\n",
    "print(\"cumsum of cols :\\n%s\" % (np.cumsum(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of y: <class 'torch.Tensor'>\n",
      "Type of y <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# pytorch world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "y = torch.from_numpy(x)\n",
    "print('Type of y:', type(y))\n",
    "y = torch.from_numpy(x).type(torch.FloatTensor)\n",
    "print('Type of y', type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x: <class 'torch.Tensor'>\n",
      "X :\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "add 5 :\n",
      "tensor([[ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.],\n",
      "        [17., 18., 19., 20.]])\n",
      "X*X^T  :\n",
      " tensor([[ 14.,  38.,  62.,  86.],\n",
      "        [ 38., 126., 214., 302.],\n",
      "        [ 62., 214., 366., 518.],\n",
      "        [ 86., 302., 518., 734.]])\n",
      "mean over cols :\n",
      " tensor([ 1.5000,  5.5000,  9.5000, 13.5000])\n",
      "cumsum of cols :\n",
      " tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [12., 15., 18., 21.],\n",
      "        [24., 28., 32., 36.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 16).view(4, 4).float()\n",
    "print('Type of x:', type(x))\n",
    "\n",
    "print(\"X :\\n%s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", torch.matmul(x, x.transpose(1, 0)))\n",
    "print(\"mean over cols :\\n\", torch.mean(x, dim=-1))\n",
    "print(\"cumsum of cols :\\n\", torch.cumsum(x, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy vs Pytorch\n",
    "\n",
    "Both Numpy and Pytorch don't require precompiled computational graph.\n",
    "\n",
    "For debug one may use pdb or debug output with print.\n",
    "\n",
    "API of NumPy and Pytorch differs slightly:\n",
    "\n",
    "```\n",
    "x.reshape([1,2,8]) -> x.view(1,2,8)\n",
    "x.sum(axis=-1) -> x.sum(dim=-1)\n",
    "x.astype('int64') -> x.type(torch.LongTensor)\n",
    "```\n",
    "\n",
    "Easy to convert:\n",
    "\n",
    "```\n",
    "torch.from_numpy(npx) -- returns Tensor\n",
    "tt.numpy() -- returns Numpy Array\n",
    "```\n",
    "\n",
    "Troubleshooting:\n",
    "- read the docs\n",
    "- google (Stackoverflow/tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 2 * np.pi, 16)\n",
    "\n",
    "# Mini-task: compute a vector of sin^2(x) + cos^2(x)\n",
    "out = torch.sin(x)**2 + torch.cos(x)**2\n",
    "\n",
    "print(out.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-place operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory must be used efficiently when working with large tensors.\n",
    "Some operations create new object as the result of computations,\n",
    "others just change given object (in-place operations).\n",
    "In pytorch, these operations usually differ by adding an underscore:\n",
    "```\n",
    "x.exp()   # not-in-place operation\n",
    "x.exp_()  # in-place operation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not-in-place:\n",
      "\tx.exp():\t\t [ 1.         2.7182817  7.389056  20.085537 ]\n",
      "\tx:\t\t\t [0. 1. 2. 3.]\n",
      "In-place:\n",
      "\tx.exp_():\t\t [ 1.         2.7182817  7.389056  20.085537 ]\n",
      "\tx after x.exp_():\t [ 1.         2.7182817  7.389056  20.085537 ]\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).float()\n",
    "print('Not-in-place:')\n",
    "print('\\tx.exp():\\t\\t', x.exp().numpy())\n",
    "print('\\tx:\\t\\t\\t', x.numpy())\n",
    "print('In-place:')\n",
    "print('\\tx.exp_():\\t\\t', x.exp_().numpy())\n",
    "print('\\tx after x.exp_():\\t', x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [4 6]]\n",
      "[[0 2]\n",
      " [4 6]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 4).view(2, 2)\n",
    "y = torch.arange(4, 8).view(2, 2)\n",
    "z = torch.arange(8, 12).view(2, 2)\n",
    "\n",
    "# Not-in-place:\n",
    "u = x + 2 * y - z    # 3 array allocations?\n",
    "print(u.numpy())\n",
    "\n",
    "# In-place\n",
    "u = y.clone()        # 1 array allocation\n",
    "u.mul_(2)\n",
    "u.add_(x)\n",
    "u.sub_(z)\n",
    "print(u.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting in pytorch (similar to numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "b: tensor([[1., 0., 1., 0.]])\n",
      "a + b: tensor([[2., 1., 2., 1.],\n",
      "        [2., 1., 2., 1.],\n",
      "        [2., 1., 2., 1.],\n",
      "        [3., 2., 3., 2.]])\n",
      "c: tensor([[-0.2284,  1.0384,  1.3887, -0.4445],\n",
      "        [ 0.3789,  0.1920,  0.5735, -0.3367],\n",
      "        [-0.9887, -0.7452,  0.4337,  0.8380],\n",
      "        [ 0.3519,  1.2024,  1.4539, -1.5165]])\n",
      "b + c: tensor([[ 0.7716,  1.0384,  2.3887, -0.4445],\n",
      "        [ 1.3789,  0.1920,  1.5735, -0.3367],\n",
      "        [ 0.0113, -0.7452,  1.4337,  0.8380],\n",
      "        [ 1.3519,  1.2024,  2.4539, -1.5165]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([1, 1, 1, 2]).view(4, 1)\n",
    "b = torch.Tensor([1, 0, 1, 0]).view(1, 4)\n",
    "c = torch.randn(16).view(4, 4)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('a + b:', a + b)\n",
    "print('c:', c)\n",
    "print('b + c:', b + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information see http://pytorch.org/docs/master/notes/broadcasting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #1: Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 objects are given, each object is 10-dimensional tensor. Also 5 points in 10-dimensional space are given. The objects and the points are stored in matrices X and Y respectively.\n",
    "\n",
    "For each object from X it is required to find an index of the nearest point from Y using only tensor operations\n",
    "(loops, list comprehensions, recursion, etc are prohibited \n",
    "because they significantly slow down the solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good solution requires $O(NM)$ additional memory instead of $O(NMD)$, where N, M, D are number of objects, number of points and the dimensinality of space respectively.\n",
    "\n",
    "Hint: you can find a matrix of pairwise scalar products between objects and points using a single matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 2, 3, 3, 1, 2, 0, 0, 1, 0,\n",
       "       4, 2, 0, 1, 0, 2, 4, 1, 4, 0, 1, 1, 0, 4, 1, 0, 1, 0, 1, 3, 1, 2,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 3, 2, 4, 0, 1, 1, 4, 3, 0, 2, 2, 3, 1, 4,\n",
       "       4, 2, 1, 1, 2, 3, 4, 1, 0, 0, 3, 4, 0, 3, 1, 3, 0, 3, 0, 1, 3, 0,\n",
       "       0, 0, 1, 4, 1, 0, 1, 1, 0, 0, 4, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 1, 2, 3, 1, 3, 1, 1, 1, 4, 1, 4, 4, 1, 1, 1, 1, 3, 3,\n",
       "       0, 1, 2, 1, 2, 1, 2, 0, 1, 2, 0, 1, 0, 2, 2, 0, 4, 2, 2, 2, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 4, 2, 0, 2, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 1,\n",
       "       2, 3, 2, 0, 3, 3, 2, 2, 1, 4, 1, 4, 1, 2, 0, 4, 2, 0, 3, 1, 1, 0, 4,\n",
       "       2, 2, 2, 2, 2, 3, 1, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU computations\n",
    "`x.cuda()` copies tensor to GPU and returns result.\n",
    "One can explicitly specify the index of the GPU on which to copy the tensor: `x.cuda(gpu_id)`.\n",
    "If the tensor is already stored on the desired GPU, then the tensor itself is returned, no copying is performed.\n",
    "`x.cpu()` works similarly.\n",
    "\n",
    "One can set `CUDA_VISIBLE_DEVICES` environment variable.\n",
    "If it is specified, then `gpu_id` is an index of a GPU the list of visible GPUs.\n",
    "\n",
    "Operations can be performed only on tensors stored on one device.\n",
    "Violation of this rule leads to an error.\n",
    "The result of the operation is on the same device as the operands.\n",
    "\n",
    "One can use `x.device` to determine on which GPU (or CPU) `x` is stored.\n",
    "To move tensor on the device `.to` is also usefull: `y.to(x.device)`.\n",
    "Also the majority of tensor constructors have optional `device` argument, e. g. `torch.randn(5, device='cuda:0')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Differentiation\n",
    "\n",
    "Gradient automatic computation using backpropagation:\n",
    "\n",
    "1. Create a tensor/tensors which requires gradient: `a = torch.tensor(..., requires_grad=True)`\n",
    "\n",
    "2. Define some differentiable _scalar_ function `loss = whatever(a)`\n",
    "\n",
    "3. Request backward pass `loss.backward()`\n",
    "\n",
    "4. The gradient is available as `a.grad`\n",
    "\n",
    "Note the loss must be a function of at least one tensor which requires gradient.\n",
    "\n",
    "For more information see https://pytorch.org/docs/stable/autograd.html\n",
    "\n",
    "The difference** between Pytorch and Theano/TensorFlow:\n",
    "\n",
    "1. The loss function can be altered dynamically, e. g. for each minibatch.\n",
    "\n",
    "2. After calling `.backward()`, gradients are stored in the `.grad` field of each involved variable. If one calls `.backward()` for several functions of the same variable, `.grad` of the variable contains the sum of gradients of those functions. One can use that to use several loss functions or virtually increase batch size. After each optimizer's step those gradients must be reset (e. g. by using `optimizer.zero_grad()`).\n",
    "\n",
    "** - now Pytorch supports computational graphs for boosting performance in production as well. It uses <a href=\"https://en.wikipedia.org/wiki/Just-in-time_compilation\">JIT</a>, so that one can easily transform their Pytorch code into TorchScript using a couple of decorators. For more information see https://pytorch.org/docs/stable/jit.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([-1.3333, -0.5294, -0.0482, -0.5393])\n",
      "y: tensor([ 1.9426,  1.1428, -1.8924,  0.5577])\n",
      "dp / dx: tensor([ 1.9426,  1.1428, -1.8924,  0.5577])\n",
      "dp / dy: tensor([-1.3333, -0.5294, -0.0482, -0.5393])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)\n",
    "y = torch.randn(4, requires_grad=True)\n",
    "z = x * y + 10\n",
    "p = z.sum()\n",
    "p.backward()\n",
    "print('x:', x.data)\n",
    "print('y:', y.data)\n",
    "print('dp / dx:', x.grad)\n",
    "print('dp / dy:', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detaching variables\n",
    "`.detach()` returns a copy of a variable, through which backpropagation doesn't pass.\n",
    "If you average or just store batch losses during the optimization, you'd better detach those losses before averaging or storing.\n",
    "Otherwise the computational graphs for each batch would be stored in memory as well as batch losses, so you run out of memory very fast.\n",
    "\n",
    "Also there is in-place version (`.detach_()`) which doesn't create detached copy of the variable, but detach variable itself from its computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([ 2.3568,  1.1385, -0.8198,  0.5400])\n",
      "y: tensor([ 1.0990, -4.3158,  2.2558,  1.3052])\n",
      "dp / dx: tensor([ 1.0990, -4.3158,  2.2558,  1.3052])\n",
      "dp / dy: None\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)\n",
    "y0 = torch.randn(4, requires_grad=True)\n",
    "y = y0.detach()\n",
    "z = x * y + 10\n",
    "p = z.sum()\n",
    "p.backward()\n",
    "print('x:', x.data)\n",
    "print('y:', y.data)\n",
    "print('dp / dx:', x.grad)\n",
    "print('dp / dy:', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "dp / dx: tensor([2., 2., 2., 2.])\n",
      "x: tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "dp / dx: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 1, 1, 1], requires_grad=True)\n",
    "y = x ** 2\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('dp / dx:', x.grad)\n",
    "y = 1 / x\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('dp / dx:', x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "dp / dx: tensor([2., 2., 2., 2.])\n",
      "x: tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "dp / dx: tensor([-1., -1., -1., -1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 1, 1, 1.], requires_grad=True)\n",
    "y = x ** 2\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('dp / dx:', x.grad)\n",
    "x.grad.detach_()       # extracting gradient Variable from the previous computational graph (optional)\n",
    "x.grad.zero_()         # zero gradinents\n",
    "y = 1 / x\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('dp / dx:', x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaf vs Non-leaf Variable\n",
    "\n",
    "For memory saving, gradients are stored only for so called `leaf-variable`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([-1.5496,  0.3766, -0.9040, -0.2435], requires_grad=True)\n",
      "y: tensor([-0.5496,  1.3766,  0.0960,  0.7565], grad_fn=<AddBackward0>)\n",
      "p: tensor(1.6795, grad_fn=<SumBackward0>)\n",
      "x.grad: tensor([1., 1., 1., 1.])\n",
      "y.grad: None\n",
      "p.grad: None\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)  # leaf variable\n",
    "y = x + 1                               # not a leaf variable\n",
    "p = y.sum()                             # not a leaf variable\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('y:', y)\n",
    "print('p:', p)\n",
    "print('x.grad:', x.grad)\n",
    "print('y.grad:', y.grad)\n",
    "print('p.grad:', p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad: tensor([1., 1., 1., 1.])\n",
      "y.grad: tensor([1., 1., 1., 1.])\n",
      "z.grad: None\n",
      "p.grad: None\n",
      "x.is_leaf: True\n",
      "y.is_leaf: True\n",
      "z.is_leaf: False\n",
      "p.is_leaf: False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)  # leaf variable\n",
    "y = torch.randn(4, requires_grad=True)  # leaf variable\n",
    "z = x + y    # not a leaf variable\n",
    "p = z.sum()  # not a leaf variable\n",
    "p.backward()\n",
    "print('x.grad:', x.grad)\n",
    "print('y.grad:', y.grad)\n",
    "print('z.grad:', z.grad)\n",
    "print('p.grad:', p.grad)\n",
    "print('x.is_leaf:', x.is_leaf)\n",
    "print('y.is_leaf:', y.is_leaf)\n",
    "print('z.is_leaf:', z.is_leaf)\n",
    "print('p.is_leaf:', p.is_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients for non-leaf variables\n",
    "One can use `.retain_grad()` to save gradients for non-leaf variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp / dx: tensor([ 1.7251,  0.8019, -2.9055,  4.9973])\n",
      "dp / dz: tensor([-3.5128,  0.0063,  1.9552, -1.8944])\n",
      "dp / dw: tensor([-1.7564,  0.0031,  0.9776, -0.9472])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)   # leaf variable\n",
    "z = torch.randn(4, requires_grad=True)   # leaf variable\n",
    "w = z * 2      # not a leaf variable\n",
    "y = x * w + 1  # forward pass before retaining gradient is ok\n",
    "p = y.sum()\n",
    "\n",
    "w.retain_grad()\n",
    "\n",
    "p.backward()\n",
    "print('dp / dx:', x.grad)\n",
    "print('dp / dz:', z.grad)\n",
    "print('dp / dw:', w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even if there are non-leaf varibales which require gradient in the computational graph, \n",
    "`.backward()` fail. For correct work one of the leaf variables must require gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a1d88584eebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/soft/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soft/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# will not work\n",
    "x = torch.randn(4, requires_grad=False)   # leaf variable\n",
    "z = torch.randn(4, requires_grad=False)   # leaf variable\n",
    "w = z * 2      # not a leaf variable\n",
    "y = x * w + 1  # forward pass before retaining gradient is ok\n",
    "p = y.sum()\n",
    "\n",
    "w.retain_grad()\n",
    "\n",
    "p.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #2: Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = torch.randn(50, 10)\n",
    "b = torch.randn(2)\n",
    "W = torch.randn(10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given some stange loss function which forces linear transformation to map 10-dimensional space points to 2-dimensional circle with radius 1. You should use gradient descent w. r. t. parameters of the transformation.\n",
    "\n",
    "Linear transformation of point 10-dimensional $x$ into 2-dimensional point $y$ has weights $W$ and $b$, and the following form:\n",
    "$$y = Wx + b$$\n",
    "\n",
    "The norm in 2-dimensional space is Euclidean:\n",
    "$$||y||_2 = \\sqrt{y_1^2 + y_2^2}$$\n",
    "\n",
    "Loss function $f_0$ penalizes the distance from $y$ to the circle with radius 1:\n",
    "$$f_0(x, W, b) = 0.5 \\cdot \\big| ||y||_2 - 1 \\big| + \\big( ||y||_2 - 1 \\big)^2$$\n",
    "\n",
    "Unfirtunatelly, the optimization of $f_0$ w. r. t. $W$ and $b$ can be derived analytically\n",
    "and leads to the trivial solution $W = 0$, $b = (1, 0)$.\n",
    "In order to avoid such solution we also penalize the proximity of $y$ to $b$. This new penalty turns to $0$ if the distance from $y$ to $b$ is larger than $1$:\n",
    "$$f_1(x, W, b) = \\max\\big(0, \\frac{1}{||y - b||_2} - 1\\big)$$\n",
    "\n",
    "The final loss function is as follows:\n",
    "$$f(x, W, b) = f_0(x, W, b) + f_1(x, W, b)$$\n",
    "\n",
    "You have to solve the optimization problem:\n",
    "$$\\frac{1}{N}\\sum\\limits_{i = 1}^N f(x_i, W, b) \\to \\min\\limits_{W, b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(X, W, b):\n",
    "    # your code here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.122261142730714\n"
     ]
    }
   ],
   "source": [
    "print(f(X, W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7fe8037048>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEyCAYAAABj+rxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fe8f6bda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "Y = X.mm(W).add(b)\n",
    "plt.scatter(Y[:, 0], Y[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842589\n",
      "0.363394\n",
      "0.307726\n",
      "0.278642\n",
      "0.262647\n",
      "0.244216\n",
      "0.222634\n",
      "0.205349\n",
      "0.197059\n",
      "0.193335\n"
     ]
    }
   ],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7fe22b0320>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEyCAYAAACYrUmUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHzNV2ksxZytnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fe22cb550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "Y = X.mm(W).add(b)\n",
    "plt.scatter(Y[:, 0], Y[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to write neural network\n",
    "Here we implement multilayer perceptron from scratch without usage of torch.nn module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1347, 64), (450, 64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: neural nets are hardly train if their inputs have large absolute values.\n",
    "That is why before training network each feature is normalized independently\n",
    "(except of convolutional networks, for them the normalization is independent only for channels).\n",
    "\n",
    "There are a lot of different ways to normalize your data.\n",
    "One of the most popular way is to subtract mean and divide the result by standard deviation\n",
    "(this method should be used carefully if standard deviation is close to zero; it is better to handle such cases separately).\n",
    "Other popular ways are subtracting median and dividing by interquartile range, mapping all values into $[-1, 1]$ by subtracting minimum and then dividing by maximum or applying sigmoid function, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should implement your data normalization here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear layer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "        self.children = []\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, *input):\n",
    "        return self.forward(*input)\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Returns list of parameters of module and its children.\"\"\"\n",
    "        res = []\n",
    "        for submodule in self.children:\n",
    "            res += submodule.parameters()\n",
    "        for param in res:\n",
    "            if not isinstance(param, torch.Tesnor):\n",
    "                raise Exception('Parameters must be Tensors.')\n",
    "            if not param.requires_grad:\n",
    "                raise Exception('Parameters must require gradients.')\n",
    "        return res\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Sets gradients of all model parameters to zero.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.grad is not None:\n",
    "                p.grad.detach_()   # detachs gradient Variable from the computational graph\n",
    "                p.grad.zero_()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Sets module into train mode (for DropOut, BatchNorm, etc).\"\"\"\n",
    "        self.training = True\n",
    "        for submodule in self.children:\n",
    "            submodule.train()\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Sets module into evaluation mode.\"\"\"\n",
    "        self.training = False\n",
    "        for submodule in self.children:\n",
    "            submodule.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseLayer(Module):\n",
    "    def __init__(self, input_units, output_units):\n",
    "        \"\"\"A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = W x + b\n",
    "        \"\"\"\n",
    "        super(Dense, self).__init__()\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "        self.weights = None  # your code here\n",
    "        self.biases = None   # your code here\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.biases]\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Performs an affine transformation:\n",
    "        f(x) = W x + b\n",
    "        input shape:  [batch, input_units]  (Tensor)\n",
    "        output shape: [batch, output units] (Tensor)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs.\"\"\"\n",
    "        super(ReLU, self).__init__()\n",
    "\n",
    "    def parameters(self):\n",
    "        return []  # ReLU has no parameters\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies elementwise ReLU to [batch, num_units] Tensor matrix.\"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogSoftmax(Module):\n",
    "    def __init__(self):\n",
    "        super(LogSoftmax, self).__init__()\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies softmax to each row and then applies component-wise log.\n",
    "        Input shape:  [batch, num_units] (Tensor)\n",
    "        Output shape: [batch, num_units] (Tensor)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyNetwork(Module):\n",
    "    def __init__(self, input_size, hidden_layers_size, hidden_layers_number, output_size):\n",
    "        super(MyNetwork, self).__init__()\n",
    "\n",
    "        network = []\n",
    "        network.append(Dense(input_size, hidden_layers_size))\n",
    "        network.append(ReLU())\n",
    "        for i in range(hidden_layers_number - 1):\n",
    "            network.append(Dense(hidden_layers_size, hidden_layers_size))\n",
    "            network.append(ReLU())\n",
    "        network.append(Dense(hidden_layers_size, output_size))\n",
    "        network.append(LogSoftmax())\n",
    "\n",
    "        self.children = network\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies all layers of neural network to the input.\n",
    "        Input shape:  [batch, num_units] (Tensor)\n",
    "        Output shape: [batch, num_units] (Tensor)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossentropy(activations, target):\n",
    "    \"\"\"Returns negative log-likelihood of target under model\n",
    "    represented by activations (log probabilities of classes).\n",
    "    Tip: it is better to average crossentropy among objects\n",
    "    instead of sum.\n",
    "    Activations shape: [batch, num_classes] (Tensor)\n",
    "    Target shape:      [batch]              (Tensor)\n",
    "    Output shape: 1 (scalar, Tensor)\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGDOptimizer:\n",
    "    def __init__(self, parameters, learning_rate):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        for param in self.parameters:\n",
    "            param.data -= self.learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(dataset, network, prefix='Test loss:', optimizer=None, verbose=True):\n",
    "    # Change mode for all layers.\n",
    "    if optimizer:\n",
    "        network.train()\n",
    "    else:\n",
    "        network.eval()\n",
    "\n",
    "    batch_size = 100\n",
    "    batchgenerator = torch.utils.data.DataLoader(dataset, batch_size, True)\n",
    "\n",
    "    avg_loss = 0\n",
    "    for i, (batch_data, batch_target) in enumerate(batchgenerator):\n",
    "        if optimizer:\n",
    "            network.zero_grad()\n",
    "        batch_output = network(batch_data)\n",
    "        batch_loss = crossentropy(batch_output, batch_target)\n",
    "        batch_loss.backward()\n",
    "        batch_loss = float(batch_loss)\n",
    "        avg_loss += (batch_loss - avg_loss) / (i + 1)\n",
    "        if optimizer:\n",
    "            optimizer.step()\n",
    "    if verbose:\n",
    "        print(prefix, avg_loss, flush=True)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.25001299381\n",
      "Test loss: 2.02255702019\n",
      "Train loss: 0.935892488275\n",
      "Test loss: 0.526892650127\n",
      "Train loss: 0.311101637781\n",
      "Test loss: 0.224462372065\n",
      "Train loss: 0.162839947534\n",
      "Test loss: 0.137114882469\n",
      "Train loss: 0.116679061204\n",
      "Test loss: 0.100092953444\n",
      "Train loss: 0.0960424696761\n",
      "Test loss: 0.0819583252072\n",
      "Train loss: 0.0743240392102\n",
      "Test loss: 0.0691537447274\n",
      "Train loss: 0.0632074608334\n",
      "Test loss: 0.0648413747549\n",
      "Train loss: 0.0556773274605\n",
      "Test loss: 0.0526380605996\n",
      "Train loss: 0.0497626392171\n",
      "Test loss: 0.0536358714104\n",
      "Train loss: 0.0436364341793\n",
      "Test loss: 0.0415103141218\n",
      "Train loss: 0.0387461567963\n",
      "Test loss: 0.0370218373835\n",
      "Train loss: 0.0330237374375\n",
      "Test loss: 0.0317714843899\n",
      "Train loss: 0.0313186772567\n",
      "Test loss: 0.0290575809777\n",
      "Train loss: 0.0266977072959\n",
      "Test loss: 0.0287078157067\n",
      "Train loss: 0.0241593799022\n",
      "Test loss: 0.0236087350175\n",
      "Train loss: 0.0228125809559\n",
      "Test loss: 0.0228643067181\n",
      "Train loss: 0.0213984650826\n",
      "Test loss: 0.0240131534636\n",
      "Train loss: 0.0181131877138\n",
      "Test loss: 0.0180235758424\n",
      "Train loss: 0.0175916215937\n",
      "Test loss: 0.0181138986722\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "sgd = SGDOptimizer(network.parameters(), 0.5)\n",
    "\n",
    "num_epochs = 20\n",
    "sgd_train_losses = []\n",
    "sgd_test_losses = []\n",
    "for i in range(num_epochs):\n",
    "    loss = run_epoch(train_dataset, network, 'Train loss:', sgd)\n",
    "    sgd_train_losses.append(loss)\n",
    "    loss = run_epoch(test_dataset, network, 'Test loss:',  None)\n",
    "    sgd_test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You need more optimizers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGDMomentumOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, momentum=0.9):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        # your code here\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RMSPropOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, beta=0.9, eps=1e-8):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta = beta\n",
    "        self.eps = eps\n",
    "        # your code here\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        # your code here\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.29899907112\n",
      "Test loss: 2.28840465546\n",
      "Train loss: 2.17900568247\n",
      "Test loss: 1.91997365952\n",
      "Train loss: 1.19421473571\n",
      "Test loss: 0.793489205837\n",
      "Train loss: 0.455302154379\n",
      "Test loss: 0.312181121111\n",
      "Train loss: 0.230511957513\n",
      "Test loss: 0.165832227468\n",
      "Train loss: 0.123873262533\n",
      "Test loss: 0.100607940555\n",
      "Train loss: 0.0892768991845\n",
      "Test loss: 0.0810534343123\n",
      "Train loss: 0.0676086062033\n",
      "Test loss: 0.0628551796079\n",
      "Train loss: 0.0543780475855\n",
      "Test loss: 0.0540404502302\n",
      "Train loss: 0.0464387893943\n",
      "Test loss: 0.0465289611369\n",
      "Train loss: 0.040847371798\n",
      "Test loss: 0.0428905472159\n",
      "Train loss: 0.037239708339\n",
      "Test loss: 0.0359449528158\n",
      "Train loss: 0.0327466359096\n",
      "Test loss: 0.0366176884621\n",
      "Train loss: 0.0296002742834\n",
      "Test loss: 0.0310783546418\n",
      "Train loss: 0.0265897470526\n",
      "Test loss: 0.0265863619745\n",
      "Train loss: 0.0248268215385\n",
      "Test loss: 0.0258533308282\n",
      "Train loss: 0.0228131134063\n",
      "Test loss: 0.0230030672625\n",
      "Train loss: 0.0207394263042\n",
      "Test loss: 0.0255728438497\n",
      "Train loss: 0.0193641397969\n",
      "Test loss: 0.0202927647159\n",
      "Train loss: 0.0178717284996\n",
      "Test loss: 0.0180073000491\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = SGDMomentumOptimizer(network.parameters(), 0.5)\n",
    "\n",
    "num_epochs = 20\n",
    "sgd_momentum_train_losses = []\n",
    "sgd_momentum_test_losses = []\n",
    "for i in range(num_epochs):\n",
    "    loss = run_epoch(train_dataset, network, 'Train loss:', sgd)\n",
    "    sgd_momentum_train_losses.append(loss)\n",
    "    loss = run_epoch(test_dataset, network, 'Test loss:',  None)\n",
    "    sgd_momentum_test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.04873784099\n",
      "Test loss: 0.38672837019\n",
      "Train loss: 0.227099137647\n",
      "Test loss: 0.188070484996\n",
      "Train loss: 0.132430793984\n",
      "Test loss: 0.121710123122\n",
      "Train loss: 0.0845916050353\n",
      "Test loss: 0.0908883780241\n",
      "Train loss: 0.0581328541573\n",
      "Test loss: 0.0690488003194\n",
      "Train loss: 0.0373754860567\n",
      "Test loss: 0.0434633551165\n",
      "Train loss: 0.0285121881004\n",
      "Test loss: 0.0349668972194\n",
      "Train loss: 0.0181794009903\n",
      "Test loss: 0.0249595091678\n",
      "Train loss: 0.0139850968761\n",
      "Test loss: 0.0204672420397\n",
      "Train loss: 0.0095160015127\n",
      "Test loss: 0.019333433453\n",
      "Train loss: 0.00756529153192\n",
      "Test loss: 0.0102690941188\n",
      "Train loss: 0.00454936275491\n",
      "Test loss: 0.0070749043487\n",
      "Train loss: 0.00344879847918\n",
      "Test loss: 0.00430776766734\n",
      "Train loss: 0.00373204343902\n",
      "Test loss: 0.00334942489862\n",
      "Train loss: 0.00152089097537\n",
      "Test loss: 0.00197805096395\n",
      "Train loss: 0.0013455981264\n",
      "Test loss: 0.00142132241745\n",
      "Train loss: 0.000820027600899\n",
      "Test loss: 0.000827933556866\n",
      "Train loss: 0.000583214284104\n",
      "Test loss: 0.000719902419951\n",
      "Train loss: 0.000449190720766\n",
      "Test loss: 0.000355705589755\n",
      "Train loss: 0.000906572375243\n",
      "Test loss: 0.000387026541284\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = RMSPropOptimizer(network.parameters())\n",
    "\n",
    "num_epochs = 20\n",
    "rmsprop_train_losses = []\n",
    "rmsprop_test_losses = []\n",
    "for i in range(num_epochs):\n",
    "    loss = run_epoch(train_dataset, network, 'Train loss:', sgd)\n",
    "    rmsprop_train_losses.append(loss)\n",
    "    loss = run_epoch(test_dataset, network, 'Test loss:',  None)\n",
    "    rmsprop_test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.984752461314\n",
      "Test loss: 0.311784574389\n",
      "Train loss: 0.334625060537\n",
      "Test loss: 0.129556299746\n",
      "Train loss: 0.147239101785\n",
      "Test loss: 0.13299726136\n",
      "Train loss: 0.0741345614993\n",
      "Test loss: 0.0770199432969\n",
      "Train loss: 0.0687923396805\n",
      "Test loss: 0.190458774939\n",
      "Train loss: 0.0397689110999\n",
      "Test loss: 0.0965252541006\n",
      "Train loss: 0.0178003121567\n",
      "Test loss: 0.040087666316\n",
      "Train loss: 0.0105867093745\n",
      "Test loss: 0.0139437015634\n",
      "Train loss: 0.00589249691049\n",
      "Test loss: 0.00134194488637\n",
      "Train loss: 0.00215421384616\n",
      "Test loss: 0.00138041300233\n",
      "Train loss: 0.00115795526654\n",
      "Test loss: 0.000901157624321\n",
      "Train loss: 0.000817922378441\n",
      "Test loss: 0.000593731965637\n",
      "Train loss: 0.00073160989684\n",
      "Test loss: 0.000453838970861\n",
      "Train loss: 0.000624272052456\n",
      "Test loss: 0.000451174081536\n",
      "Train loss: 0.000591980269486\n",
      "Test loss: 0.00039646657533\n",
      "Train loss: 0.000536981753872\n",
      "Test loss: 0.000367731397273\n",
      "Train loss: 0.000519900157607\n",
      "Test loss: 0.000337578472681\n",
      "Train loss: 0.000461065433878\n",
      "Test loss: 0.000309497537091\n",
      "Train loss: 0.000445698657651\n",
      "Test loss: 0.000284600986197\n",
      "Train loss: 0.000420782158991\n",
      "Test loss: 0.000307945412351\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = AdamOptimizer(network.parameters())\n",
    "\n",
    "num_epochs = 20\n",
    "adam_train_losses = []\n",
    "adam_test_losses = []\n",
    "for i in range(num_epochs):\n",
    "    loss = run_epoch(train_dataset, network, 'Train loss:', sgd)\n",
    "    adam_train_losses.append(loss)\n",
    "    loss = run_epoch(test_dataset, network, 'Test loss:',  None)\n",
    "    adam_test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sgd_train_losses, label='SGD train')\n",
    "plt.plot(sgd_test_losses, label='SGD test')\n",
    "plt.plot(sgd_momentum_train_losses, label='SGD momentum train')\n",
    "plt.plot(sgd_momentum_test_losses, label='SGD momentum test')\n",
    "plt.plot(rmsprop_train_losses, label='Rmsprop train')\n",
    "plt.plot(rmsprop_test_losses, label='Rmsprop test')\n",
    "plt.plot(adam_train_losses, label='Adam train')\n",
    "plt.plot(adam_test_losses, label='Adam test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseWithDropOut(Module):\n",
    "    def __init__(self, input_units, output_units, dropout_rate, nonlinearity):\n",
    "        \"\"\"A dense layer is a layer which performs a learned\n",
    "        affine transformation and applies dropout:\n",
    "        m ~ Bernoulli(1 - p, size=output_units)\n",
    "        f(x) = g(W x + b) o m\n",
    "        \"\"\"\n",
    "        super(DenseWithDropOut, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.nonlinearity = nonlinearity\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "        self.weights = None  # your code here\n",
    "        self.biases = None   # your code here\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.biases]\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Performs an affine transformation with dropout.\n",
    "        In training mode:\n",
    "        m ~ Bernoulli(1 - p, size=output_units)\n",
    "        f(x) = g(W x + b) o m\n",
    "        In evaluation mode:\n",
    "        f(x) = g(W x + b) (1 - p)\n",
    "        input shape:  [batch, input_units]  (Variable)\n",
    "        output shape: [batch, output units] (Variable)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether it is true that a fully connected network with a dropout works faster than a regular fully connected network, since smaller passes are calculated on each pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54 s ± 191 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "7.3 s ± 954 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "width = 2000\n",
    "network1 = [\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, 1, 0, lambda x: x)\n",
    "]\n",
    "network2 = [\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, 1)\n",
    "]\n",
    "X = torch.randn(10000, width)\n",
    "\n",
    "# check whether DenseWithDropOut works faster than Dense\n",
    "def test_network(network):\n",
    "    x = Variable(X)\n",
    "    for layer in network:\n",
    "        x = layer.forward(x)\n",
    "    x.mean().backward()\n",
    "    for layer in network:\n",
    "        x = layer.zero_grad()\n",
    "\n",
    "test_network(network1)\n",
    "%timeit test_network(network1)\n",
    "%timeit test_network(network2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For narrower layers, lower dropout rate and smaller batch sizes, the performance increase is not so significant or may be completely absent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
